{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from datasets import concatenate_datasets, load_dataset"
   ],
   "id": "f006a5f54571ea0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Reading the raw dataset.",
   "id": "1a77d091769edef8"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "ds = load_dataset(\n",
    "    \"pszemraj/goodreads-bookgenres\",\n",
    "    \"default\",\n",
    "    revision=\"c4b00cd5b71cfb62687ddbd0e9c1c9d6a06e8d80\"\n",
    ")\n",
    "df = concatenate_datasets(ds.values()).to_pandas()\n",
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dropping useless columns.",
   "id": "1d7a4c7bece5b941"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df.drop(columns=[\"Book\"])",
   "id": "b6fbd2caf39b1813",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dropping rows with missing data.",
   "id": "1decdf712cbf2012"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df.dropna()",
   "id": "8dbd9a70099c7ddf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Renaming columns.",
   "id": "181767126fbfb022"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df.rename(columns={\"Description\": \"body\", \"Genres\": \"genres\"})",
   "id": "4e6636980d435539",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dropping rows with potentially politically ambiguous genres.",
   "id": "aed74d0c3879dc3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "genres = [\n",
    "    \"History & Politics\",\n",
    "    \"Health & Medicine\",\n",
    "    \"Mystery & Thriller\",\n",
    "    \"Arts & Design\",\n",
    "    \"Self-Help & Wellness\",\n",
    "    \"Sports & Recreation\",\n",
    "    \"Non-Fiction\",\n",
    "    \"Science Fiction & Fantasy\",\n",
    "    \"Countries & Geography\",\n",
    "    \"Other\",\n",
    "    \"Nature & Environment\",\n",
    "    \"Business & Finance\",\n",
    "    \"Romance\",\n",
    "    \"Philosophy & Religion\",\n",
    "    \"Literature & Fiction\",\n",
    "    \"Science & Technology\",\n",
    "    \"Children & Young Adult\",\n",
    "    \"Food & Cooking\",\n",
    "]\n",
    "\n",
    "ambiguous_genre_indexes = [\n",
    "    genres.index(ambiguous_genre) for ambiguous_genre in [\n",
    "        \"History & Politics\",\n",
    "        \"Other\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "df = df[df[\"genres\"].apply(lambda genres: not any(genres[index] == 1 for index in ambiguous_genre_indexes))]"
   ],
   "id": "91f1b3bc5519659b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dropping useless columns.",
   "id": "f20bd570e8947cd3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df.drop(columns=[\"genres\"])",
   "id": "179cf8e243b9d536",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Printing duplicates.",
   "id": "deb5653b24590b68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[df[\"body\"].duplicated(keep=False)]",
   "id": "54cf2cfe9a82e886",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dropping the duplicates.",
   "id": "c74ff49322d5eb3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = df.drop_duplicates(subset=\"body\")",
   "id": "933f5131d3dd3ad4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Adding the politicalness label column.",
   "id": "d814f07fa252fda1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[\"politicalness\"] = pd.Categorical([\"non-political\"] * len(df))",
   "id": "17aed87dc4f0ddcb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Inspecting body length.",
   "id": "e39a9b1ad88c5890"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"body_length\"] = df[\"body\"].str.len()\n",
    "df[\"body_word_count\"] = df[\"body\"].str.split().str.len()\n",
    "df = df.sort_values(by=\"body_length\")\n",
    "df.head()"
   ],
   "id": "9b7b57ab04ccd38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[\"body_length\"].mean()",
   "id": "5bcddd2a321b8f1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ensuring to include the last (longest) item.\n",
    "downsampled = pd.concat([df[\"body_length\"].iloc[::100], df[\"body_length\"].tail(1)]).drop_duplicates()\n",
    "downsampled.plot.bar().xaxis.set_ticks([]);"
   ],
   "id": "ede6ac13d07cc5be",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.to_parquet(\"../preprocessed/goodreads_bookgenres.parquet\")",
   "id": "b0e42a22a87ab15d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
