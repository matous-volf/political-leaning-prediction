{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "\n",
    "import datasets\n",
    "from datasets import DatasetInfo, concatenate_datasets\n",
    "from transformers import IntervalStrategy\n",
    "\n",
    "from utils import dataset_utils\n",
    "from utils.dataset_utils import get_politicalness_datasets, \\\n",
    "    get_politicalness_datasets_from_leaning_datasets_for_leave_one_out_benchmark, \\\n",
    "    leaning_with_center_label_mapping\n",
    "from utils.model_utils import finetune_models"
   ],
   "id": "65a87d9dbe948a82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "TRAINING_POLITICAL_LEANING = False\n",
    "RESULT_SUBDIRECTORY_NAME = \"political_leaning\"\n",
    "GET_DATASETS = lambda: chain(\n",
    "    get_politicalness_datasets(),\n",
    "    get_politicalness_datasets_from_leaning_datasets_for_leave_one_out_benchmark()\n",
    ")\n",
    "TEST_DATASET_SAMPLE_PART = 0.15\n",
    "EVAL_DATASET_SAMPLE_SIZE = 10_000\n",
    "TRAIN_DATASET_SAMPLE_SIZE = 10_000\n",
    "\n",
    "CENTER_LEANING_CLASS_SIZE_MULTIPLIERS = {\n",
    "    \"article_bias_prediction\": 5,\n",
    "    \"bignewsbln\": 10,  # There is not enough center leaning examples to balance this out.\n",
    "    \"commoncrawl_news_articles\": 5.5,\n",
    "    \"gpt4_political_bias\": 3.25,\n",
    "    \"gpt4_political_ideologies\": 3,\n",
    "    \"qbias\": 3.25,\n",
    "}\n",
    "CENTER_LEANING_CLASS_SIZE_MULTIPLIER_DEFAULT = 2.6\n",
    "\n",
    "whole_datasets = list(GET_DATASETS())\n",
    "\n",
    "for dataset in whole_datasets:\n",
    "    print(dataset.name, round(len(dataset.dataframe) * TEST_DATASET_SAMPLE_PART))\n",
    "    test_dataset = dataset.take_even_class_distribution_sample(round(len(dataset.dataframe) * TEST_DATASET_SAMPLE_PART))\n",
    "    # Remove the test sample from the source dataframe.\n",
    "    dataset.dataframe = dataset.dataframe.loc[~dataset.dataframe.index.isin(test_dataset.dataframe.index)]\n",
    "\n",
    "eval_datasets = []\n",
    "for dataset in whole_datasets:\n",
    "    dataset = dataset.take_even_class_distribution_sample(EVAL_DATASET_SAMPLE_SIZE)\n",
    "    dataset = dataset.transform_for_inference(\n",
    "        leaning_with_center_label_mapping if TRAINING_POLITICAL_LEANING else None\n",
    "    )\n",
    "    eval_datasets.append(dataset.to_huggingface())\n",
    "\n",
    "\n",
    "def get_train_dataset(left_out_dataset: dataset_utils.Dataset) -> datasets.Dataset:\n",
    "    train_datasets_separate = []\n",
    "\n",
    "    for dataset in filter(\n",
    "            lambda dataset: dataset.name != left_out_dataset.name,\n",
    "            whole_datasets,\n",
    "    ):\n",
    "        if TRAINING_POLITICAL_LEANING:\n",
    "            dataset = dataset.take_balanced_class_distribution_sample(\n",
    "                TRAIN_DATASET_SAMPLE_SIZE,\n",
    "                CENTER_LEANING_CLASS_SIZE_MULTIPLIERS[left_out_dataset.name]\n",
    "                if left_out_dataset.name in CENTER_LEANING_CLASS_SIZE_MULTIPLIERS.keys()\n",
    "                else CENTER_LEANING_CLASS_SIZE_MULTIPLIER_DEFAULT\n",
    "            )\n",
    "            dataset = dataset.transform_for_inference(\n",
    "                leaning_with_center_label_mapping\n",
    "            )\n",
    "        else:\n",
    "            dataset.take_even_class_distribution_sample(TRAIN_DATASET_SAMPLE_SIZE)\n",
    "            dataset = dataset.transform_for_inference()\n",
    "\n",
    "        train_datasets_separate.append(dataset.to_huggingface())\n",
    "\n",
    "    dataset = concatenate_datasets(\n",
    "        train_datasets_separate,\n",
    "        info=DatasetInfo(dataset_name=left_out_dataset.name)\n",
    "    )\n",
    "    print(left_out_dataset.name)\n",
    "    print(dataset.to_pandas().groupby(\"label\").count())\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_datasets = [\n",
    "    get_train_dataset(left_out_dataset) for left_out_dataset in whole_datasets\n",
    "]"
   ],
   "id": "cec1aed2eafd6a3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "TRAINING_SEED = 37\n",
    "DATA_SEED = 37\n",
    "EVAL_STRATEGY = IntervalStrategy.EPOCH\n",
    "\n",
    "finetune_models(\n",
    "    Path(\"dataset_benchmark\", \"leave_one_out\", RESULT_SUBDIRECTORY_NAME),\n",
    "    train_datasets,\n",
    "    eval_datasets,\n",
    "    EVAL_STRATEGY,\n",
    "    TRAINING_SEED,\n",
    "    DATA_SEED\n",
    ")"
   ],
   "id": "bb09a7eec1dd2c5c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
