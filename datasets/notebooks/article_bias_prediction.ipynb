{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Reading the raw dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIRECTORY = \"../raw/article_bias_prediction\"\n",
    "data = []\n",
    "for filename in os.listdir(DATASET_DIRECTORY):\n",
    "    filepath = os.path.join(DATASET_DIRECTORY, filename)\n",
    "    with open(filepath, \"r\") as file:\n",
    "        data.append(json.load(file))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Dropping useless columns. The content column is\n",
    "> the processed and tokenized content, which is used as input to the different models\n",
    "\n",
    "and so the original content can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"topic\", \"bias\", \"source\", \"url\", \"date\", \"authors\", \"content_original\", \"source_url\", \"ID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Renaming and reordering columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"content\": \"body\", \"bias_text\": \"leaning\"})\n",
    "df = df[[\"title\", \"body\", \"leaning\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Categorizing the leaning column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"leaning\"] = df[\"leaning\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Dropping rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"body\", \"leaning\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Printing duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"body\"].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Dropping the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=\"body\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Inspecting body length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"body_length\"] = df[\"body\"].str.len()\n",
    "df[\"body_word_count\"] = df[\"body\"].str.split().str.len()\n",
    "df = df.sort_values(by=\"body_length\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "After inspection, articles with bodies shorter than 40 words seem to contain no political value. Removing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_word_count_lower_bound = 40\n",
    "df = df[df[\"body_word_count\"] >= body_word_count_lower_bound]\n",
    "# Ensuring to include the last (longest) item.\n",
    "downsampled = pd.concat([df[\"body_length\"].iloc[::100], df[\"body_length\"].tail(1)]).drop_duplicates()\n",
    "downsampled.plot.bar().xaxis.set_ticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"body_length\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "The leaning distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"leaning\", observed=True).size().plot.pie(autopct=\"%1.1f%%\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "The distribution of body length sums per leaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"leaning\", observed=True)[\"body_length\"].sum().plot.pie(autopct=\"%1.1f%%\", ylabel=\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Body length distribution by leaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for leaning in df[\"leaning\"].unique():\n",
    "    df_leaning = df[df[\"leaning\"] == leaning]\n",
    "    downsampled = pd.concat(\n",
    "        # Ensuring to include the last (longest) item.\n",
    "        [df_leaning[\"body_length\"].iloc[::100], df_leaning[\"body_length\"].tail(1)]\n",
    "    ).drop_duplicates().reset_index(drop=True)\n",
    "    plt.plot(downsampled, label=leaning)\n",
    "\n",
    "plt.xlabel(\"downsampled index\")\n",
    "plt.ylabel(\"body length\")\n",
    "plt.title(\"body length by political leaning\")\n",
    "plt.legend(title=\"leaning\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../preprocessed/article_bias_prediction.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
