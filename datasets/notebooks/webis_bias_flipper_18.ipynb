{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from io import StringIO\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sympy.physics.control.control_plots import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Reading the raw dataset. Some rows (e.g. line 1010) contain complex nested quotes and commas, which requires modifying each line before passing it to `pandas.read_csv()`. The outer quotes get replaced by an arbitrary (`\\u2603`, the snowman) character, which is then specified as the quote character used for parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.field_size_limit(4 * 131072)  # 4 times the default\n",
    "\n",
    "with open(\"../raw/webis_bias_flipper_18.csv\", mode=\"r\", encoding=\"utf-8\") as file:\n",
    "    modified_lines = (\n",
    "        \"\\u2603\".join(line.replace(\"\\\",\\\"\", \"\\u2603,\\u2603\").replace(\"\\\"\", \"\\u2603\", 1).rsplit(\"\\\"\", 1))\n",
    "        for line in file\n",
    "    )\n",
    "    df = pd.read_csv(StringIO(\"\".join(modified_lines)), quotechar=\"\\u2603\", encoding=\"utf-8\", engine=\"python\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Comparison of the body column (from AllSides) versus the original body column (from the news portals). The text volume of the original columns is much higher, probably because AllSides cuts the length. This means the title and body columns can be dropped and the original ones will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(\n",
    "    [df[\"original_body\"].str.len().sum(), df[\"body\"].str.len().sum()],\n",
    "    index=[\"original body\", \"body\"]\n",
    ").plot.pie(autopct=\"%1.1f%%\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Dropping useless columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"story_id\", \"title\", \"body\", \"source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Renaming and reordering columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"original_title\": \"title\", \"original_body\": \"body\", \"bias\": \"leaning\"})\n",
    "df = df[[\"title\", \"body\", \"leaning\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Categorizing the leaning column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"leaning\"] = df[\"leaning\"].astype(\"category\")\n",
    "df[\"leaning\"] = df[\"leaning\"].cat.rename_categories(\n",
    "    {\"From the Left\": \"left\", \"From the Center\": \"center\", \"From the Right\": \"right\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Printing duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"body\"].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Dropping the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=\"body\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Inspecting body length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"body_length\"] = df[\"body\"].str.len()\n",
    "df[\"body_word_count\"] = df[\"body\"].str.split().str.len()\n",
    "df.sort_values(by=\"body_length\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by=\"body_length\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Calculating the bounds for body length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = np.percentile(df[\"body_length\"], 25)\n",
    "q3 = np.percentile(df[\"body_length\"], 75)\n",
    "iqr = q3 - q1\n",
    "lower_bound_multiplier = 0.5\n",
    "upper_bound_multiplier = 9\n",
    "lower_bound = q1 - lower_bound_multiplier * iqr\n",
    "upper_bound = q3 + upper_bound_multiplier * iqr\n",
    "lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Removing the outliers based on the body length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df[\"body_length\"] >= lower_bound) & (df[\"body_length\"] <= upper_bound)]\n",
    "body_length = df[\"body_length\"].sort_values()\n",
    "# Ensuring to include the last (longest) item.\n",
    "downsampled = pd.concat([body_length.iloc[::100], body_length.iloc[[-1]]]).drop_duplicates()\n",
    "downsampled.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "The leaning distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"leaning\", observed=True).size().plot.pie(autopct=\"%1.1f%%\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "This dataset is basically a subset of the Webis-News-Bias-20 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"../preprocessed/webis_news_bias_20.csv\")\n",
    "print(len(df))\n",
    "pd.Series(list(set(df[\"title\"]).intersection(set(df2[\"title\"])))).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../preprocessed/webis_news_bias_20.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
