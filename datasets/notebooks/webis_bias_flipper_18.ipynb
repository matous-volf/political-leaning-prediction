{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas import Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Reading the raw dataset. Some rows (e.g. line 1010) contain complex nested quotes and commas, which requires modifying each line before passing it to `pandas.read_csv()`. The outer quotes get replaced by an arbitrary (`\\u2603`, the snowman) character, which is then specified as the quote character used for parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.field_size_limit(4 * 131072)  # 4 times the default\n",
    "\n",
    "with open(\"../raw/webis_bias_flipper_18.csv\", mode=\"r\", encoding=\"utf-8\") as file:\n",
    "    modified_lines = (\n",
    "        \"\\u2603\".join(line.replace(\"\\\",\\\"\", \"\\u2603,\\u2603\").replace(\"\\\"\", \"\\u2603\", 1).rsplit(\"\\\"\", 1))\n",
    "        for line in file\n",
    "    )\n",
    "    df = pd.read_csv(StringIO(\"\".join(modified_lines)), quotechar=\"\\u2603\", encoding=\"utf-8\", engine=\"python\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Comparison of the body column (from AllSides) versus the original body column (from the news portals). The text volume of the original columns is much higher, probably because AllSides cuts the length. This means the title and body columns can be dropped and the original ones will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(\n",
    "    [df[\"original_body\"].str.len().sum(), df[\"body\"].str.len().sum()],\n",
    "    index=[\"original body\", \"body\"]\n",
    ").plot.pie(autopct=\"%1.1f%%\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Dropping useless columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"story_id\", \"title\", \"body\", \"source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "Renaming and reordering columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"original_title\": \"title\", \"original_body\": \"body\", \"bias\": \"leaning\"})\n",
    "df = df[[\"title\", \"body\", \"leaning\"]].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Categorizing the leaning column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"leaning\"] = df[\"leaning\"].astype(\"category\")\n",
    "df[\"leaning\"] = df[\"leaning\"].cat.rename_categories(\n",
    "    {\"From the Left\": \"left\", \"From the Center\": \"center\", \"From the Right\": \"right\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "Dropping rows with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"body\", \"leaning\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "Printing duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"body\"].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Dropping the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=\"body\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Inspecting body length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"body_length\"] = df[\"body\"].str.len()\n",
    "df[\"body_word_count\"] = df[\"body\"].str.split().str.len()\n",
    "df = df.sort_values(by=\"body_length\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "After inspection, articles with bodies shorter than 15 words seem to contain no political value. Removing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_word_count_lower_bound = 15\n",
    "df = df[df[\"body_word_count\"] >= body_word_count_lower_bound]\n",
    "# Ensuring to include the last (longest) item.\n",
    "downsampled = pd.concat([df[\"body_length\"].iloc[::10], df[\"body_length\"].tail(1)]).drop_duplicates()\n",
    "downsampled.plot.bar().xaxis.set_ticks([]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"body_length\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "The leaning distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"leaning\", observed=True).size().plot.pie(autopct=\"%1.1f%%\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "The distribution of body length sums per leaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"leaning\", observed=True)[\"body_length\"].sum().plot.pie(autopct=\"%1.1f%%\", ylabel=\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Body length distribution by leaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for leaning in df[\"leaning\"].unique():\n",
    "    df_leaning = df[df[\"leaning\"] == leaning]\n",
    "    downsampled = pd.concat(\n",
    "        # Ensuring to include the last (longest) item.\n",
    "        [df_leaning[\"body_length\"].iloc[::10], Series(df_leaning[\"body_length\"].tail(1))]\n",
    "    ).drop_duplicates().reset_index(drop=True)\n",
    "    plt.plot(downsampled, label=leaning)\n",
    "\n",
    "plt.xlabel(\"downsampled index\")\n",
    "plt.ylabel(\"body length\")\n",
    "plt.title(\"body length by political leaning\")\n",
    "plt.legend(title=\"leaning\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"../preprocessed/webis_bias_flipper_18.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
